import torch
import sys
import os
import subprocess
import shutil
import tempfile
import uuid
import gradio as gr
from glob import glob
from huggingface_hub import snapshot_download
from tqdm.notebook import tqdm  # –î–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞ –≤ Colab

print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SVFR...")

# Download models
os.makedirs("models", exist_ok=True)
print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...")

snapshot_download(
    repo_id = "fffiloni/SVFR",
    local_dir = "./models",
    tqdm_class=tqdm  # –ò—Å–ø–æ–ª—å–∑—É–µ–º tqdm –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
)

# List of subdirectories to create inside "checkpoints"
subfolders = [
    "stable-video-diffusion-img2vid-xt"
]
# Create each subdirectory
for subfolder in subfolders:
    os.makedirs(os.path.join("models", subfolder), exist_ok=True)

print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Stable Video Diffusion...")
snapshot_download(
    repo_id = "stabilityai/stable-video-diffusion-img2vid-xt",
    local_dir = "./models/stable-video-diffusion-img2vid-xt",
    tqdm_class=tqdm  # –ò—Å–ø–æ–ª—å–∑—É–µ–º tqdm –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
)

print("\n‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")

def infer(lq_sequence, task_name):
    try:
        print("üîÑ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ...")
        
        # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å GPU –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º
        if torch.cuda.is_available():
            print("üßπ –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ GPU...")
            torch.cuda.empty_cache()
            import gc
            gc.collect()
            
            # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏
            print(f"üíæ –î–æ—Å—Ç—É–ø–Ω–∞—è –ø–∞–º—è—Ç—å GPU: {torch.cuda.get_device_properties(0).total_memory/1e9:.2f}GB")
            print(f"üíæ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–∞–º—è—Ç–∏: {torch.cuda.memory_allocated()/1e9:.2f}GB")
        
        unique_id = str(uuid.uuid4())
        output_dir = f"results_{unique_id}"

        if task_name == "BFR":
            task_id = "0"
        elif task_name == "colorization":
            task_id = "1"
        elif task_name == "BFR + colorization":
            task_id = "0,1"
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ—Ü–µ—Å—Å–∞
        env = os.environ.copy()
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏, —Ç–∞–∫ –∫–∞–∫ —É –Ω–∞—Å 12GB VRAM
        env['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128,garbage_collection_threshold:0.8'
        env['CUDA_LAUNCH_BLOCKING'] = '1'
        env['PYTORCH_NO_CUDA_MEMORY_CACHING'] = '1'
        env['CUDA_VISIBLE_DEVICES'] = '0'
        
        # –†–∞–∑—Ä–µ—à–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–æ 90% –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏
        if torch.cuda.is_available():
            torch.cuda.set_per_process_memory_fraction(0.9)
            
        print(f"üíæ –ù–∞—Å—Ç—Ä–æ–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ GPU: –¥–æ 90% –æ—Ç {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB")
        
        print("üöÄ –ó–∞–ø—É—Å–∫ inference...")
        # –ó–∞–ø—É—Å–∫–∞–µ–º inference —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø–∞–º—è—Ç–∏ –∏ –ø–µ—Ä–µ—Ö–≤–∞—Ç–æ–º –≤—ã–≤–æ–¥–∞
        process = subprocess.run(
            [
                "python", "infer.py",
                "--config", "config/infer.yaml",
                "--task_ids", f"{task_id}",
                "--input_path", f"{lq_sequence}",
                "--output_dir", f"{output_dir}",
            ],
            check=True,
            env=env,
            capture_output=True,
            text=True
        )
        
        # –í—ã–≤–æ–¥–∏–º –ª–æ–≥–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞
        if process.stdout:
            print("üìù –í—ã–≤–æ–¥ –ø—Ä–æ—Ü–µ—Å—Å–∞:")
            print(process.stdout)
        if process.stderr:
            print("‚ö†Ô∏è –û—à–∏–±–∫–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞:")
            print(process.stderr)

        # Search for the mp4 file in a subfolder of output_dir
        output_video = glob(os.path.join(output_dir,"*.mp4"))
        
        if output_video:
            output_video_path = output_video[0]
            print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {output_video_path}")
            return output_video_path
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤—ã—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ")
            raise gr.Error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤—ã—Ö–æ–¥–Ω–æ–µ –≤–∏–¥–µ–æ")
    
    except subprocess.CalledProcessError as e:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            gc.collect()
        error_msg = f"Stdout: {e.stdout}\nStderr: {e.stderr}" if hasattr(e, 'stdout') else str(e)
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {error_msg}")
        raise gr.Error(f"Error during inference: {error_msg}")
    except Exception as e:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            gc.collect()
        print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        raise gr.Error(f"Unexpected error: {str(e)}")
    finally:
        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        try:
            for old_dir in glob("results_*"):
                if os.path.isdir(old_dir):
                    shutil.rmtree(old_dir, ignore_errors=True)
            print("üßπ –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ: {e}")

css="""
div#col-container{
    margin: 0 auto;
    max-width: 982px;
}
"""
with gr.Blocks(css=css) as demo:
    with gr.Column(elem_id="col-container"):
        gr.Markdown("# SVFR: A Unified Framework for Generalized Video Face Restoration")
        gr.Markdown("SVFR is a unified framework for face video restoration that supports tasks such as BFR, Colorization, Inpainting, and their combinations within one cohesive system.")
        gr.HTML("""
        <div style="display:flex;column-gap:4px;">
            <a href="https://github.com/wangzhiyaoo/SVFR">
                <img src='https://img.shields.io/badge/GitHub-Repo-blue'>
            </a> 
            <a href="https://wangzhiyaoo.github.io/SVFR/">
                <img src='https://img.shields.io/badge/Project-Page-green'>
            </a>
            <a href="https://arxiv.org/pdf/2501.01235">
                <img src='https://img.shields.io/badge/ArXiv-Paper-red'>
            </a>
            <a href="https://huggingface.co/spaces/fffiloni/SVFR-demo?duplicate=true">
                <img src="https://huggingface.co/datasets/huggingface/badges/resolve/main/duplicate-this-space-sm.svg" alt="Duplicate this Space">
            </a>
            <a href="https://huggingface.co/fffiloni">
                <img src="https://huggingface.co/datasets/huggingface/badges/resolve/main/follow-me-on-HF-sm-dark.svg" alt="Follow me on HF">
            </a>
        </div>
        """)
        with gr.Row():
            with gr.Column():
                input_seq = gr.Video(label="Video LQ")
                task_name = gr.Radio(
                    label="Task", 
                    choices=["BFR", "colorization", "BFR + colorization"], 
                    value="BFR"
                )
                submit_btn = gr.Button("Submit")
            with gr.Column():
                output_res = gr.Video(label="Restored")
                gr.Examples(
                    examples = [
                        ["./assert/lq/lq1.mp4", "BFR"],
                        ["./assert/lq/lq2.mp4", "BFR + colorization"],
                        ["./assert/lq/lq3.mp4", "colorization"]
                    ],
                    inputs = [input_seq, task_name]
                )
    
    submit_btn.click(
        fn = infer,
        inputs = [input_seq, task_name],
        outputs = [output_res]
    )

demo.queue().launch(show_api=False, show_error=True)
